#!/usr/bin/env python
# coding=utf-8
"""
Web3 èµ„è®¯æŠ“å–ä¸æ¨é€è„šæœ¬

åŠŸèƒ½ï¼š
1. æŠ“å– Web3 ä¿¡æ¯æºï¼ˆChainCatcherã€Cointelegraph ç­‰ï¼‰
2. ç”Ÿæˆèµ„è®¯ç®€æŠ¥å¹¶ä¿å­˜ä¸º HTML æŠ¥å‘Š
3. æ¨é€åˆ°é…ç½®çš„æ¸ é“ï¼ˆä¼ä¸šå¾®ä¿¡ã€Telegram ç­‰ï¼‰

ä½¿ç”¨æ–¹æ³•ï¼š
    python run_web3_push.py              # æ­£å¸¸è¿è¡Œï¼ˆæŠ“å– + ä¿å­˜ + æ¨é€ï¼‰
    python run_web3_push.py --test       # æµ‹è¯•æ¨¡å¼ï¼ˆåªæŠ“å–ä¸æ¨é€ï¼‰
    python run_web3_push.py --dry-run    # é¢„è§ˆæ¨¡å¼ï¼ˆæ˜¾ç¤ºå°†è¦æ¨é€çš„å†…å®¹ï¼‰
    python run_web3_push.py --no-save    # ä¸ä¿å­˜åˆ°æ–‡ä»¶
"""

import os
import sys
import json
import argparse
from datetime import datetime

# ä¿®å¤ Windows ç»ˆç«¯ç¼–ç é—®é¢˜
if sys.platform == "win32":
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# Web3 ç›¸å…³çš„ RSS æº ID
# è®¾ç½®ä¸º None è¡¨ç¤ºæŠ“å–æ‰€æœ‰å·²å¯ç”¨çš„ RSS æº
# å¦‚éœ€é™åˆ¶ï¼Œå¯è®¾ç½®ä¸ºåˆ—è¡¨ï¼Œä¾‹å¦‚: ["cointelegraph", "coindesk"]
WEB3_RSS_IDS = None


def load_config():
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    import yaml

    config_path = os.path.join(os.path.dirname(__file__), "config", "config.yaml")

    if not os.path.exists(config_path):
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        sys.exit(1)

    with open(config_path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)


def crawl_web3_rss_sources(config):
    """æŠ“å–æ‰€æœ‰å·²å¯ç”¨çš„ RSS ä¿¡æ¯æº"""
    from trendradar.crawler.rss.fetcher import RSSFetcher

    rss_config = config.get("rss", {})
    if not rss_config.get("enabled", True):
        print("â„¹ï¸ RSS æŠ“å–å·²ç¦ç”¨")
        return None

    # è·å–æ‰€æœ‰å·²å¯ç”¨çš„ feeds
    original_feeds = rss_config.get("feeds", [])

    # å¦‚æœ WEB3_RSS_IDS ä¸º Noneï¼ŒæŠ“å–æ‰€æœ‰å·²å¯ç”¨çš„æº
    # å¦åˆ™åªæŠ“å–æŒ‡å®šçš„æº
    if WEB3_RSS_IDS is None:
        enabled_feeds = [f for f in original_feeds if f.get("enabled", True)]
    else:
        enabled_feeds = [f for f in original_feeds if f.get("id") in WEB3_RSS_IDS and f.get("enabled", True)]

    if not enabled_feeds:
        print("â„¹ï¸ æ²¡æœ‰å¯ç”¨çš„ RSS æº")
        return None

    # åˆ›å»º RSS é…ç½®
    rss_fetch_config = rss_config.copy()
    rss_fetch_config["feeds"] = enabled_feeds
    rss_fetch_config["timezone"] = config.get("app", {}).get("timezone", "Asia/Shanghai")

    print(f"[RSS] å…± {len(enabled_feeds)} ä¸ªå·²å¯ç”¨çš„ RSS æº")
    for feed in enabled_feeds:
        print(f"       - {feed.get('name', feed.get('id'))}")

    fetcher = RSSFetcher.from_config(rss_fetch_config)
    return fetcher.fetch_all()


def crawl_web3_sources(config):
    """æŠ“å– Web3 è‡ªå®šä¹‰çˆ¬è™«ä¿¡æ¯æº"""
    from trendradar.crawler.web3.fetcher import Web3Fetcher, Web3FeedConfig

    web3_config = config.get("web3", {})
    if not web3_config.get("enabled", True):
        print("â„¹ï¸ Web3 çˆ¬è™«å·²ç¦ç”¨")
        return None

    # æ„å»ºé…ç½®
    feeds = []
    for feed_config in web3_config.get("feeds", []):
        if not feed_config.get("enabled", True):
            continue

        feed = Web3FeedConfig(
            id=feed_config.get("id", ""),
            name=feed_config.get("name", ""),
            url=feed_config.get("url", ""),
            crawler_type=feed_config.get("crawler_type", ""),
            max_items=feed_config.get("max_items", 50),
            enabled=True,
            max_age_days=feed_config.get("max_age_days"),
        )
        if feed.id and feed.crawler_type:
            feeds.append(feed)

    if not feeds:
        print("â„¹ï¸ æ²¡æœ‰å¯ç”¨çš„ Web3 çˆ¬è™«æº")
        return None

    fetcher = Web3Fetcher(
        feeds=feeds,
        request_interval=web3_config.get("request_interval", 3000),
        timeout=web3_config.get("timeout", 30),
        use_proxy=web3_config.get("use_proxy", False),
        proxy_url=web3_config.get("proxy_url", ""),
        timezone=config.get("app", {}).get("timezone", "Asia/Shanghai"),
    )

    return fetcher.fetch_all()


def collect_all_items(rss_data, web3_data):
    """æ”¶é›†æ‰€æœ‰æ–°é—»æ¡ç›®"""
    all_items = []

    # æ”¶é›† RSS æ•°æ®
    if rss_data and rss_data.items:
        for feed_id, items in rss_data.items.items():
            feed_name = rss_data.id_to_name.get(feed_id, feed_id)
            for item in items:
                all_items.append({
                    "title": item.title,
                    "url": item.url,
                    "source": feed_name,
                    "source_id": feed_id,
                    "time": item.published_at,
                    "summary": getattr(item, 'summary', '') or '',
                    "type": "rss",
                })

    # æ”¶é›† Web3 çˆ¬è™«æ•°æ®
    if web3_data and web3_data.items:
        for feed_id, items in web3_data.items.items():
            feed_name = web3_data.id_to_name.get(feed_id, feed_id)
            for item in items:
                all_items.append({
                    "title": item.title,
                    "url": item.url,
                    "source": feed_name,
                    "source_id": feed_id,
                    "time": item.published_at,
                    "summary": getattr(item, 'summary', '') or '',
                    "type": "web3",
                })

    # æŒ‰æ—¶é—´æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    all_items.sort(key=lambda x: x.get("time") or "", reverse=True)

    return all_items


def format_report(all_items, config, max_items=20):
    """æ ¼å¼åŒ–æ¨é€æŠ¥å‘Šï¼ˆMarkdown æ ¼å¼ï¼‰"""
    from trendradar.utils.time import get_configured_time

    timezone = config.get("app", {}).get("timezone", "Asia/Shanghai")
    now = get_configured_time(timezone)

    lines = []
    lines.append(f"**[Web3 èµ„è®¯æ—¥æŠ¥]** {now.strftime('%Y-%m-%d')}")
    lines.append("")
    lines.append("---")
    lines.append("")

    if not all_items:
        lines.append("æš‚æ— æ–°èµ„è®¯")
    else:
        lines.append("**ğŸ“° ä»Šæ—¥çƒ­ç‚¹**")
        lines.append("")

        for i, item in enumerate(all_items[:max_items], 1):
            title = item["title"][:55] + "..." if len(item["title"]) > 55 else item["title"]
            source = item["source"]
            lines.append(f"{i}. [{title}]({item['url']})")
            lines.append(f"   > æ¥æº: {source}")
            lines.append("")

    lines.append("---")
    lines.append("")

    # ç»Ÿè®¡ä¿¡æ¯
    sources = set(item["source"] for item in all_items)
    lines.append(f"ğŸ“Š æ•°æ®æ¥æº: {len(sources)} ä¸ªå¹³å° | å…± {len(all_items)} æ¡èµ„è®¯")
    lines.append(f"ğŸ• æ›´æ–°æ—¶é—´: {now.strftime('%H:%M')}")

    return "\n".join(lines)


def save_json_data(all_items, output_dir, date_str, time_str):
    """ä¿å­˜ JSON æ•°æ®"""
    json_dir = os.path.join(output_dir, "web3", date_str)
    os.makedirs(json_dir, exist_ok=True)

    json_path = os.path.join(json_dir, f"{time_str}.json")

    data = {
        "date": date_str,
        "time": time_str,
        "total_count": len(all_items),
        "items": all_items,
    }

    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    print(f"[SAVE] JSON æ•°æ®å·²ä¿å­˜: {json_path}")
    return json_path


def generate_html_report(all_items, config, output_dir, date_str, time_str):
    """ç”Ÿæˆè¶…ç‚«é…· HTML æŠ¥å‘Š - èµ›åšæœ‹å…‹é£æ ¼"""
    from trendradar.utils.time import get_configured_time
    from web3_html_template import generate_cyber_html

    timezone = config.get("app", {}).get("timezone", "Asia/Shanghai")
    now = get_configured_time(timezone)
    now_str = now.strftime('%Y-%m-%d %H:%M:%S')

    html_dir = os.path.join(output_dir, "web3", date_str, "html")
    os.makedirs(html_dir, exist_ok=True)

    # æŒ‰æ¥æºåˆ†ç»„ç»Ÿè®¡
    source_stats = {}
    for item in all_items:
        source = item["source"]
        source_stats[source] = source_stats.get(source, 0) + 1

    # ä½¿ç”¨æ–°çš„ç‚«é…·æ¨¡æ¿ç”Ÿæˆ HTML
    html_content = generate_cyber_html(all_items, source_stats, date_str, time_str, now_str)

    # ä¿å­˜ HTML æ–‡ä»¶
    html_path = os.path.join(html_dir, f"{time_str}.html")
    with open(html_path, 'w', encoding='utf-8') as f:
        f.write(html_content)

    # ä¿å­˜æ±‡æ€»æ–‡ä»¶
    summary_path = os.path.join(html_dir, "Web3èµ„è®¯æ±‡æ€».html")
    with open(summary_path, 'w', encoding='utf-8') as f:
        f.write(html_content)

    # åˆ›å»ºæ ¹ç›®å½•çš„ index.htmlï¼Œç›´æ¥åµŒå…¥æ±‡æ€»æŠ¥å‘Šå†…å®¹ï¼Œé¿å…é‡å®šå‘é—®é¢˜
    # ç›´æ¥ä½¿ç”¨æ±‡æ€»æŠ¥å‘Šçš„ HTML å†…å®¹ï¼Œä¸éœ€è¦é‡å®šå‘
    index_html = html_content

    # ä¿å­˜åˆ° output æ ¹ç›®å½•
    root_index_path = os.path.join(output_dir, "index.html")
    with open(root_index_path, 'w', encoding='utf-8') as f:
        f.write(index_html)

    print(f"[SAVE] HTML æŠ¥å‘Šå·²ä¿å­˜: {html_path}")
    print(f"[SAVE] æ±‡æ€»æŠ¥å‘Šå·²ä¿å­˜: {summary_path}")
    print(f"[SAVE] é¦–é¡µå·²ä¿å­˜: {root_index_path}")

    return html_path, summary_path


def push_to_wework(content, config):
    """æ¨é€åˆ°ä¼ä¸šå¾®ä¿¡"""
    import requests

    notification_config = config.get("notification", {})
    if not notification_config.get("enabled", False):
        print("[INFO] æ¨é€åŠŸèƒ½æœªå¯ç”¨")
        return False

    wework_config = notification_config.get("channels", {}).get("wework", {})
    webhook_url = wework_config.get("webhook_url", "")

    if not webhook_url:
        print("[WARN] ä¼ä¸šå¾®ä¿¡ webhook_url æœªé…ç½®")
        return False

    msg_type = wework_config.get("msg_type", "markdown")

    if msg_type == "markdown":
        payload = {
            "msgtype": "markdown",
            "markdown": {"content": content}
        }
    else:
        # text æ¨¡å¼ï¼Œç§»é™¤ markdown è¯­æ³•
        import re
        plain_content = re.sub(r'\[([^\]]+)\]\([^\)]+\)', r'\1', content)
        plain_content = plain_content.replace("**", "").replace("*", "")
        payload = {
            "msgtype": "text",
            "text": {"content": plain_content}
        }

    try:
        response = requests.post(
            webhook_url,
            json=payload,
            headers={"Content-Type": "application/json"},
            timeout=30
        )

        result = response.json()
        if result.get("errcode") == 0:
            print("[OK] ä¼ä¸šå¾®ä¿¡æ¨é€æˆåŠŸ âœ…")
            return True
        else:
            print(f"[FAIL] ä¼ä¸šå¾®ä¿¡æ¨é€å¤±è´¥: {result.get('errmsg')}")
            return False

    except Exception as e:
        print(f"[ERROR] ä¼ä¸šå¾®ä¿¡æ¨é€å‡ºé”™: {e}")
        return False


def push_to_telegram(content, config):
    """æ¨é€åˆ° Telegram"""
    import requests

    notification_config = config.get("notification", {})
    if not notification_config.get("enabled", False):
        return False

    telegram_config = notification_config.get("channels", {}).get("telegram", {})
    bot_token = telegram_config.get("bot_token", "")
    chat_id = telegram_config.get("chat_id", "")

    if not bot_token or not chat_id:
        return False

    # è½¬æ¢ä¸º Telegram æ”¯æŒçš„æ ¼å¼
    import re
    text = re.sub(r'\[([^\]]+)\]\(([^\)]+)\)', r'<a href="\2">\1</a>', content)
    text = text.replace("**", "<b>").replace("**", "</b>")
    text = text.replace("---", "â€”" * 20)

    try:
        url = f"https://api.telegram.org/bot{bot_token}/sendMessage"
        payload = {
            "chat_id": chat_id,
            "text": text,
            "parse_mode": "HTML",
            "disable_web_page_preview": True
        }

        response = requests.post(url, json=payload, timeout=30)
        result = response.json()

        if result.get("ok"):
            print("[OK] Telegram æ¨é€æˆåŠŸ âœ…")
            return True
        else:
            print(f"[FAIL] Telegram æ¨é€å¤±è´¥: {result.get('description')}")
            return False

    except Exception as e:
        print(f"[ERROR] Telegram æ¨é€å‡ºé”™: {e}")
        return False


def open_html_report(html_path):
    """åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ HTML æŠ¥å‘Š"""
    import webbrowser

    abs_path = os.path.abspath(html_path)
    file_url = f"file://{abs_path}"

    print(f"[OPEN] æ­£åœ¨æ‰“å¼€æŠ¥å‘Š: {file_url}")
    webbrowser.open(file_url)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="Web3 èµ„è®¯æŠ“å–ä¸æ¨é€")
    parser.add_argument("--test", action="store_true", help="æµ‹è¯•æ¨¡å¼ï¼ˆåªæŠ“å–ä¸æ¨é€ï¼‰")
    parser.add_argument("--dry-run", action="store_true", help="é¢„è§ˆæ¨¡å¼ï¼ˆæ˜¾ç¤ºå°†è¦æ¨é€çš„å†…å®¹ï¼‰")
    parser.add_argument("--no-save", action="store_true", help="ä¸ä¿å­˜æ•°æ®åˆ°æ–‡ä»¶")
    parser.add_argument("--no-open", action="store_true", help="ä¸è‡ªåŠ¨æ‰“å¼€ HTML æŠ¥å‘Š")
    args = parser.parse_args()

    print()
    print("=" * 60)
    print("  ğŸŒ Web3 èµ„è®¯æŠ“å–ä¸æ¨é€ç³»ç»Ÿ")
    print(f"  ğŸ“… æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    print()

    # åŠ è½½é…ç½®
    print("[1/5] åŠ è½½é…ç½®...")
    config = load_config()
    print("[OK] é…ç½®åŠ è½½æˆåŠŸ âœ…")
    print()

    # æŠ“å– Web3 RSS æ•°æ®
    print("[2/5] æŠ“å– Web3 RSS ä¿¡æ¯æº...")
    rss_data = crawl_web3_rss_sources(config)
    rss_count = rss_data.get_total_count() if rss_data else 0
    print(f"[OK] Web3 RSS æŠ“å–å®Œæˆ: {rss_count} æ¡ âœ…")
    print()

    # æŠ“å– Web3 çˆ¬è™«æ•°æ®
    print("[3/5] æŠ“å– Web3 çˆ¬è™«ä¿¡æ¯æº...")
    web3_data = crawl_web3_sources(config)
    web3_count = web3_data.get_total_count() if web3_data else 0
    print(f"[OK] Web3 çˆ¬è™«æŠ“å–å®Œæˆ: {web3_count} æ¡ âœ…")
    print()

    # æ”¶é›†æ‰€æœ‰æ•°æ®
    all_items = collect_all_items(rss_data, web3_data)
    print(f"[INFO] å…±æ”¶é›† {len(all_items)} æ¡ Web3 èµ„è®¯")
    print()

    # ç”ŸæˆæŠ¥å‘Š
    print("[4/5] ç”Ÿæˆæ¨é€æŠ¥å‘Š...")
    report = format_report(all_items, config)
    print("[OK] æŠ¥å‘Šç”Ÿæˆå®Œæˆ âœ…")
    print()

    # ä¿å­˜æ•°æ®
    if not args.no_save:
        print("[5/5] ä¿å­˜æ•°æ®...")
        output_dir = os.path.join(os.path.dirname(__file__), "output")
        date_str = datetime.now().strftime("%Y-%m-%d")
        time_str = datetime.now().strftime("%H-%M")

        # ä¿å­˜ JSON
        save_json_data(all_items, output_dir, date_str, time_str)

        # ç”Ÿæˆ HTML
        html_path, summary_path = generate_html_report(all_items, config, output_dir, date_str, time_str)

        print("[OK] æ•°æ®ä¿å­˜å®Œæˆ âœ…")
        print()

        # è‡ªåŠ¨æ‰“å¼€ HTML
        if not args.no_open and not args.test:
            open_html_report(summary_path)
    else:
        print("[5/5] è·³è¿‡ä¿å­˜ï¼ˆ--no-saveï¼‰")
        print()

    # é¢„è§ˆæ¨¡å¼
    if args.dry_run or args.test:
        print("=" * 60)
        print("  ğŸ“‹ æ¨é€å†…å®¹é¢„è§ˆ")
        print("=" * 60)
        print()
        print(report)
        print()
        print("=" * 60)

        if args.test:
            print("[OK] æµ‹è¯•å®Œæˆï¼ˆæœªå®é™…æ¨é€ï¼‰âœ…")
            return 0

    # æ¨é€
    if not args.test:
        print("[PUSH] å¼€å§‹æ¨é€...")
        print()

        # ä¼ä¸šå¾®ä¿¡
        push_to_wework(report, config)

        # Telegram
        push_to_telegram(report, config)

        print()
        print("=" * 60)
        print("  âœ… æ¨é€å®Œæˆ")
        print("=" * 60)

    return 0


if __name__ == "__main__":
    try:
        sys.exit(main())
    except KeyboardInterrupt:
        print("\n\n[WARN] ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\n[ERROR] è¿è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
